# Requisitos:
# pip install langchain-openai langchain-core python-dotenv pydantic

import os
import dotenv
from pydantic import BaseModel
from langchain_openai import AzureChatOpenAI  # integraciÃ³n Azure en LangChain
from langchain_core.output_parsers.json import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers.pydantic import PydanticOutputParser
dotenv.load_dotenv()

AZURE_OPENAI_API_KEY = os.getenv("AZURE_INFERENCE_SDK_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_INFERENCE_SDK_ENDPOINT")
DEPLOYMENT_NAME = os.getenv("DEPLOYMENT_NAME")  # eg. "phi-4"
API_VERSION = os.getenv("OPENAI_API_VERSION", "2024-03-01-preview")

# 1. Modelo Pydantic para salida estructurada
class RespuestaClinica(BaseModel):
    intencion: str
    valido: bool
    respuesta: str

# 2. Parser con JsonOutputParser
parser = PydanticOutputParser(pydantic_object=RespuestaClinica)

# 3. Plantilla de prompt con CoT y formateo
prompt = PromptTemplate(
    template="""
Eres un asistente profesional de DentalCare Tacna. Solo respondes preguntas sobre servicios, citas, horarios o contacto.

Sigue estos pasos (Chainâ€‘ofâ€‘Thought):
1. Detecta intenciÃ³n.
2. Verifica si es relevante para la clÃ­nica.
3. Decide si responder o rechazar.
4. Si respondes, hazlo en mÃ¡ximo 3 frases.
5. Devuelve un JSON con los campos: intencion, valido, respuesta.

{format_instructions}

Mensaje del usuario:
{mensaje}
""",
    input_variables=["mensaje"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

# 4. Configura el cliente LLM de Azure
llm = AzureChatOpenAI(
    openai_api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    azure_deployment=DEPLOYMENT_NAME,
    api_version=API_VERSION,
    temperature=0.7,
)

# 5. Construye la cadena LangChain: prompt â†’ LLM â†’ parser
chain = prompt | llm | parser

# 6. FunciÃ³n para responder solo con el campo "respuesta"
def responder_azure(mensaje_usuario: str) -> str:
    try:
        resultado: RespuestaClinica = chain.invoke({"mensaje": mensaje_usuario})
        return resultado.respuesta
    except Exception as e:
        print("âŒ Error:", e)
        return "Lo siento, ocurriÃ³ un error procesando tu mensaje."

# ğŸ§ª Prueba bÃ¡sica
if __name__ == "__main__":
    print(responder_azure("Â¿CuÃ¡l es su horario de atenciÃ³n?"))
